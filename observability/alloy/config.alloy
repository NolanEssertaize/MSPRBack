// observability/alloy/config.alloy - Configuration simplifiée avec support traces
// Configuration Grafana Alloy pour Plant Care Application - Version avec traces

// =====================================================
// DÉCOUVERTE DES SERVICES
// =====================================================

// Découverte des conteneurs Docker
discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"

  filter {
    name   = "label"
    values = ["observability=enabled"]
  }
}

// =====================================================
// COLLECTE DES LOGS (simplifiée pour éviter rate limiting)
// =====================================================

// Logs des conteneurs Docker - filtrés
loki.source.docker "docker_logs" {
  host       = "unix:///var/run/docker.sock"
  targets    = discovery.docker.containers.targets

  forward_to = [loki.process.plant_care.receiver]

  relabel_rules = loki.relabel.docker_logs.rules
}

// Relabeling pour les logs Docker
loki.relabel "docker_logs" {
  forward_to = []

  rule {
    source_labels = ["__meta_docker_container_name"]
    target_label  = "container"
  }

  rule {
    source_labels = ["__meta_docker_container_image"]
    target_label  = "image"
  }

  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "service"
  }

  // Filtrer seulement les logs d'erreur et importants pour éviter le spam
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "plant_care_api"
    target_label  = "__tmp_should_include"
    replacement   = "yes"
  }
}

// Traitement simplifié des logs
loki.process "plant_care" {
  forward_to = [loki.write.default.receiver]

  // Filtrer les logs health check pour réduire le volume
  stage.match {
    selector = "{job=\"syslog\"}"
    action   = "drop"
  }

  stage.json {
    expressions = {
      level     = "level",
      timestamp = "timestamp", 
      message   = "message",
      service   = "service",
    }
  }

  stage.labels {
    values = {
      level   = "",
      service = "",
    }
  }

  stage.output {
    source = "message"
  }
}

// Écriture vers Loki avec retry
loki.write "default" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
    
    // Configuration pour éviter les erreurs de rate limit
    max_backoff_period = "5m"
    max_backoff_retries = 10
  }
}

// =====================================================
// COLLECTE DES TRACES - CONFIGURATION PRINCIPALE
// =====================================================

// Réception des traces OTLP depuis l'application
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    traces  = [otelcol.processor.batch.default.input]
    logs    = [otelcol.processor.batch.otel_logs.input]
    metrics = [otelcol.processor.batch.metrics.input]
  }
}

// Traitement en lot des traces avec configuration optimisée
otelcol.processor.batch "default" {
  // Configuration pour de meilleures performances
  send_batch_size = 1024
  timeout = "1s"
  send_batch_max_size = 2048

  output {
    traces = [otelcol.processor.attributes.traces.input]
  }
}

// Ajout d'attributs de ressource pour améliorer l'observabilité
otelcol.processor.attributes "traces" {

  output {
    traces = [otelcol.exporter.otlp.tempo.input]
  }
}

// Export vers Tempo avec configuration robuste
otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "http://tempo:4317"
    tls {
      insecure = true
    }
    
  }
}

// Traitement des logs OTLP
otelcol.processor.batch "otel_logs" {
  output {
    logs = [otelcol.exporter.loki.default.input]
  }
}

// Export des logs OTLP vers Loki
otelcol.exporter.loki "default" {
  forward_to = [loki.write.default.receiver]
}

// Traitement des métriques OTLP
otelcol.processor.batch "metrics" {
  output {
    metrics = [otelcol.exporter.prometheus.default.input]
  }
}

// Export des métriques OTLP vers Prometheus
otelcol.exporter.prometheus "default" {
  forward_to = [prometheus.remote_write.prometheus.receiver]
}

// =====================================================
// COLLECTE DES MÉTRIQUES - VERSION PROMETHEUS
// =====================================================

// Métriques des conteneurs Docker
prometheus.scrape "docker_containers" {
  targets    = discovery.docker.containers.targets
  forward_to = [prometheus.relabel.docker_metrics.receiver]

  scrape_interval = "15s"
  metrics_path    = "/metrics"
}

// Relabeling pour les métriques Docker
prometheus.relabel "docker_metrics" {
  forward_to = [prometheus.remote_write.prometheus.receiver]

  rule {
    source_labels = ["__meta_docker_container_name"]
    target_label  = "container"
  }

  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "service"
  }
}

// Remote write vers Prometheus
prometheus.remote_write "prometheus" {
  endpoint {
    url = "http://prometheus:9090/api/v1/write"
    
    // Configuration pour retry
    queue_config {
      capacity = 10000
      max_samples_per_send = 2000
      batch_send_deadline = "5s"
    }
  }
}

// =====================================================
// LOGGING DE DEBUG ET MÉTRIQUES INTERNES
// =====================================================

// Logs internes d'Alloy avec niveau debug pour traces
logging {
  level  = "info"
  format = "logfmt"
}

// Exposition des métriques internes d'Alloy
prometheus.exporter.self "alloy" {}

prometheus.scrape "alloy_self" {
  targets    = prometheus.exporter.self.alloy.targets
  forward_to = [prometheus.relabel.alloy_metrics.receiver]

  scrape_interval = "15s"
}

// Relabeling pour Alloy
prometheus.relabel "alloy_metrics" {
  forward_to = [prometheus.remote_write.prometheus.receiver]

  rule {
    target_label = "service"
    replacement  = "alloy"
  }
}
